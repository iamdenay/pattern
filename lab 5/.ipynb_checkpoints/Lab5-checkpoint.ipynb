{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 5\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ -7.02761245e-01,   3.64881044e-01,   5.90913803e-02],\n",
      "       [  9.24591919e-01,   8.57748006e-01,   6.34187612e-06],\n",
      "       [ -7.58204282e-01,   5.60276260e-01,   8.71066628e-01]]), array([[ 0.8388258 ],\n",
      "       [-0.12816584],\n",
      "       [ 0.13992448]])]\n",
      "('epochs:', 0)\n",
      "('epochs:', 10000)\n",
      "('epochs:', 20000)\n",
      "('epochs:', 30000)\n",
      "('epochs:', 40000)\n",
      "('epochs:', 50000)\n",
      "('epochs:', 60000)\n",
      "('epochs:', 70000)\n",
      "('epochs:', 80000)\n",
      "('epochs:', 90000)\n",
      "(array([0, 0]), 0)\n",
      "(array([0, 1]), 1)\n",
      "(array([1, 0]), 1)\n",
      "(array([1, 1]), 0)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104e97490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.errors = []\n",
    "        self.activation = sigmoid\n",
    "        self.activation_prime = sigmoid_prime\n",
    "\n",
    "\n",
    "        self.weights = []\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) - 1\n",
    "            self.weights.append(r)\n",
    "            # output layer - random((2+1, 1)) : 3 x 1\n",
    "            r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "            self.weights.append(r)\n",
    "            \n",
    "        print(self.weights)\n",
    "            \n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000, momentum=1):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            allError = 0;\n",
    "            for i in range(X.shape[0]):\n",
    "                a = [X[i]]\n",
    "\n",
    "                for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "                # output layer\n",
    "                error = y[i]\n",
    "                if a[-1] > 0.5:\n",
    "                    error -= 1\n",
    "                allError += abs(error)\n",
    "                deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "                # we need to begin at the second to last layer \n",
    "                # (a layer before the output layer)\n",
    "                for l in range(len(a) - 2, 0, -1): \n",
    "                    deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "                # reverse\n",
    "                # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "                deltas.reverse()\n",
    "\n",
    "                # backpropagation\n",
    "                # 1. Multiply its output delta and input activation \n",
    "                #    to get the gradient of the weight.\n",
    "                # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "                prev_weights_delta = [0] * len(self.weights)\n",
    "                for i in range(len(self.weights)):\n",
    "                    layer = np.atleast_2d(a[i])\n",
    "                    delta = np.atleast_2d(deltas[i])\n",
    "#                     self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "                    \n",
    "                    # ref: https://jamesmccaffrey.wordpress.com/2017/06/06/neural-network-momentum/\n",
    "                    delta = learning_rate * layer.T.dot(delta)\n",
    "                    self.weights[i] += delta\n",
    "                    self.weights[i] += momentum * prev_weights_delta[i]\n",
    "                    prev_weights_delta[i] = delta\n",
    "                                        \n",
    "            self.errors.append(allError/4)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "                \n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))\n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        \n",
    "        res = 0\n",
    "        if a > 0.5:\n",
    "            res = 1\n",
    "        return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))\n",
    "        \n",
    "    plt.plot(range(len(nn.errors)),nn.errors)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
